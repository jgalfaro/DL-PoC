{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Material to:\n",
    "# Blueprint for Next Generation Cyber-Physical Resilience using Defense Quantum Machine - Learning Two-train Example\n",
    "# Authors\n",
    "\n",
    "Michel Barbeau\n",
    "\n",
    "Joaquin Garcia-Alfaro\n",
    "\n",
    "Version: September 12, 2021\n",
    "\n",
    "We reused code from: \n",
    "<a href=\"https://pennylane.ai/qml/demos/tutorial_qubit_rotation.html\">Basic tutorial: qubit rotation</a>\n",
    "   \n",
    "Note: This example runs of version 0.8.0 of Pennylane, which is not the *defaul latest version*. To force installation of that version, in a Linux shell enter:\n",
    "\n",
    "python -m pip install pennylane==0.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-train scenario\n",
    "\n",
    "Let us consider the following discrete two-train scenario:\n",
    "\n",
    "   ![track](two_train.png)\n",
    "\n",
    "Tracks are broken into sections.\n",
    "Let us assume a scenario where Train 1 is the agent and Train 2 is part of its world.\n",
    "There is an outer loop visiting points 3, 4 and 5,\n",
    "together with a bypass from point 2, visiting point 8 to point 6.\n",
    "Traversal time is uniform across sections.\n",
    "The normal trajectory of Train 1 is the outer loop,\n",
    "while maintaining a Train 2-Train 1 distance greater than one empty section.\n",
    "For example, if Train 1 is at point 0 while\n",
    "Train 2 is at point 7, then\n",
    "the separation distance constraint is violated.\n",
    "The goal of the adversary is to steer the system in a state where the separation distance constraint is violated.\n",
    "When a train crosses point 0,\n",
    "it has to make a choice: either traverse the outer loop or take the bypass.\n",
    "Both trains can follow any path and make independent choices, \n",
    "when they are at point 0.\n",
    "\n",
    "In the terms of reinforcement learning,\n",
    "Train 1 has two actions available: take loop and take bypass.\n",
    "The agent gets $k$ reward points for a relative Train 2-Train 1 distance increase of $k$ sections with Train 2.\n",
    "It gets $-k$ reward points, i.e., a penalty, \n",
    "for a relative Train 2-Train 1 distance decrease of $k$ sections with Train 2.\n",
    "For example, let us assume that Train 1 is at point 0 and that Train 2 is at point 7.\n",
    "If both trains, progressing a the same speed, take the loop or both  decide to take the bypass,\n",
    "then there is no relative distance change.\n",
    "The agent gets no reward.\n",
    "When Train 1 decides to take the bypass and Train 2 decides to take the loop,\n",
    "the agent gets two reward points,\n",
    "at return to point zero (Train 2 is at point five).\n",
    "When Train 1 decides to take the loop and Train 2 decides to take the bypass,\n",
    "the agent gets four reward points,\n",
    "at return to point zero (Train 2 is at point one, Train 2-Train 1 distance is five sections).\n",
    "\n",
    "The representation of the environment is as follows: \n",
    "\n",
    "   ![track](MDP_two_trains.png)\n",
    "\n",
    "The state set is $S=\\{ 0, 1,2 \\}$.\n",
    "The action set is $A=\\{ a_0=\\mbox{take loop},  a_1=\\mbox{take bypass} \\}$\n",
    "The transition probability function is defined as $P_{a_0}(0,0)=p$,   $P_{a_0}(0,1)=1-p$, $P_{a_1}(0,0)=q$ and $P_{a_1}(0,2)=1-q$.\n",
    "The reward functions is defined as $R_{a_0}(0,0)=0$, $R_{a_0}(0,1)=4$, $R_{a_1}(0,0)=0$ and $R_{a_1}(0,2)=2$.\n",
    "This is interpreted as follows.\n",
    "In the initial state $0$ with a one-section separation distance,\n",
    "the agent selects an action to perform: take loop or take bypass.\n",
    "Train 1 performs the selected action.\n",
    "When selecting take loop,\n",
    "with probability $p$ the environment goes back to state $0$ (no reward) or with probability $1-p$ it moves to state $1$,\n",
    "with a five-section separation distance (reward is four).\n",
    "When selecting take bypass,\n",
    "with probability $q$ the environment goes back to state $0$ (no reward) or with probability $1-q$ it moves state $2$,\n",
    "with a three-section separation distance (reward is two).\n",
    "The agent memorizes how good it has been to perform a selected action.\n",
    "\n",
    "In the sequel, the environment probabilities of zero reward $p$ and $q$ are assumed to be the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  PennyLan environment import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev1 = qml.device(\"default.qubit\", wires=1, shots=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum node construction\n",
    "\n",
    "A variational circuit `W(theta)` is trained, with parameter `theta`. The circuit consists of two gates: an $X$ gate and an $Y$ gate. In this example, there is only state $S_0$. It is represented by the quantum state $\\vert 0 \\rangle$. Because it is a ground state, the state is not coded explicitly at the input of the circuit. Parameter `theta` is an array of two rotation angles, one for every gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev1)\n",
    "def W(theta):\n",
    "    qml.RX(theta[0], wires=0)\n",
    "    qml.RY(theta[1], wires=0)\n",
    "    # return probabilities of computational basis states\n",
    "    return qml.probs(wires=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost model\n",
    "\n",
    "The actions take loop and take bypass are respectively represented by the quantum states $\\vert 0 \\rangle$ and $\\vert 1 \\rangle$. The variational circuit is trained on the probability of each computational basis state: $\\vert 0 \\rangle$ and $\\vert 1 \\rangle$.\n",
    "\n",
    "The `cost` function measures the difference between the probablities associated to the variational circuit `W(theta)` and the target probabilities of the quantum states $\\vert 0 \\rangle$ and $\\vert 1 \\rangle$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(X, Y):\n",
    "    loss = 0\n",
    "    for x, y in zip(X, Y):\n",
    "        loss = loss + (x - y) ** 2\n",
    "    return loss / len(X)\n",
    "\n",
    "def cost(theta, p):\n",
    "    #  p is prob. of ket zero, 1-p is prob of ket 1\n",
    "    return square_loss(W(theta), [p, 1-p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Quantum circuit update\n",
    "\n",
    "Using optimization, the following code finds the `theta` such that the variational circuit `W(theta)` outputs a quantum state where the probabilities $\\vert 0 \\rangle$ and $\\vert 1 \\rangle$ are respectively $p$ and $1-p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial probs. of basis states: [0.61432696 0.38567304]\n"
     ]
    }
   ],
   "source": [
    "# initialise the optimizer\n",
    "opt = qml.GradientDescentOptimizer(stepsize=0.4)\n",
    "# set the number of steps\n",
    "steps = 10\n",
    "# set the initial theta value of variational circuit state\n",
    "theta = np.random.randn(2)\n",
    "print(\"Initial probs. of basis states: {}\".format(W(theta)))\n",
    "\n",
    "def update(theta, p):\n",
    "    # p = probability\n",
    "    for i in range(steps):\n",
    "        # update the circuit parameters\n",
    "        theta = opt.step(lambda v: cost(v, p), theta)\n",
    "        #if (i + 1) % 10 == 0:\n",
    "            #print(\"Cost @ step {:5d}: {: .7f}\".format(i, cost(theta,p)))\n",
    "    #print(\"Probs. of basis states: {}\".format(W(theta)))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement learning process\n",
    "\n",
    "Q Learning Reinforcement Learning is used. \n",
    "\n",
    "Probabilities of quantum states $\\vert 0 \\rangle$ and $\\vert 1 \\rangle$ is proportional to the respective rewards `Q[0]/(Q[0]+Q[1])` and `1 - Q[0]/(Q[0]+Q[1])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0  num:  0.7660289091569452  action:  1  reward:  2  Q-values:  [0, 0.02]\n",
      "i:  1  num:  0.6615408941707992  action:  0  reward:  4  Q-values:  [0.04, 0.02]\n",
      "i:  2  num:  0.2466746113257663  action:  1  reward:  2  Q-values:  [0.04, 0.04]\n",
      "i:  3  num:  0.7363505370675982  action:  0  reward:  4  Q-values:  [0.08, 0.04]\n",
      "i:  4  num:  0.6986184730653854  action:  1  reward:  2  Q-values:  [0.08, 0.060000000000000005]\n",
      "i:  5  num:  0.6909053769921761  action:  1  reward:  2  Q-values:  [0.08, 0.08]\n",
      "i:  6  num:  0.07019156256758963  action:  1  reward:  2  Q-values:  [0.08, 0.1]\n",
      "i:  7  num:  0.752087680104352  action:  0  reward:  4  Q-values:  [0.12000000000000001, 0.1]\n",
      "i:  8  num:  0.4535136016360577  action:  1  reward:  2  Q-values:  [0.12000000000000001, 0.12000000000000001]\n",
      "i:  9  num:  0.1776527591072955  action:  0  reward:  4  Q-values:  [0.16, 0.12000000000000001]\n",
      "i:  10  num:  0.07769326466333237  action:  1  reward:  2  Q-values:  [0.16, 0.14]\n",
      "i:  11  num:  0.11089427642296668  action:  1  reward:  2  Q-values:  [0.16, 0.16]\n",
      "i:  12  num:  0.9681559764460075  action:  0  reward:  4  Q-values:  [0.2, 0.16]\n",
      "i:  13  num:  0.1940035265691964  action:  0  reward:  4  Q-values:  [0.24000000000000002, 0.16]\n",
      "i:  14  num:  0.881540467506921  action:  0  reward:  4  Q-values:  [0.28, 0.16]\n",
      "i:  15  num:  0.19500779011928748  action:  0  reward:  4  Q-values:  [0.32, 0.16]\n",
      "i:  16  num:  0.7229852114745271  action:  0  reward:  4  Q-values:  [0.36000000000000004, 0.16]\n",
      "i:  17  num:  0.5250627871445339  action:  0  reward:  4  Q-values:  [0.4000000000000001, 0.16]\n",
      "i:  18  num:  0.7695918002398373  action:  1  reward:  2  Q-values:  [0.4000000000000001, 0.18000000000000002]\n",
      "i:  19  num:  0.7795873838121119  action:  0  reward:  4  Q-values:  [0.44000000000000006, 0.18000000000000002]\n",
      "i:  20  num:  0.9953744482751442  action:  1  reward:  2  Q-values:  [0.44000000000000006, 0.20000000000000004]\n",
      "i:  21  num:  0.7395567172871411  action:  0  reward:  4  Q-values:  [0.48000000000000004, 0.20000000000000004]\n",
      "i:  22  num:  0.9032454349134023  action:  1  reward:  2  Q-values:  [0.48000000000000004, 0.22000000000000003]\n",
      "i:  23  num:  0.44527439084969633  action:  0  reward:  4  Q-values:  [0.52, 0.22000000000000003]\n",
      "i:  24  num:  0.24578654025092617  action:  1  reward:  2  Q-values:  [0.52, 0.24000000000000002]\n",
      "i:  25  num:  0.5687397358360422  action:  1  reward:  2  Q-values:  [0.52, 0.26]\n",
      "i:  26  num:  0.11863508330902517  action:  1  reward:  2  Q-values:  [0.52, 0.28]\n",
      "i:  27  num:  0.4942915355813542  action:  0  reward:  4  Q-values:  [0.56, 0.28]\n",
      "i:  28  num:  0.880540094925226  action:  0  reward:  4  Q-values:  [0.6, 0.28]\n",
      "i:  29  num:  0.49483148397180265  action:  0  reward:  4  Q-values:  [0.64, 0.28]\n",
      "i:  30  num:  0.7947119478394646  action:  0  reward:  4  Q-values:  [0.68, 0.28]\n",
      "i:  31  num:  0.7199012608846255  action:  1  reward:  2  Q-values:  [0.68, 0.3]\n",
      "i:  32  num:  0.9188622970277083  action:  1  reward:  2  Q-values:  [0.68, 0.32]\n",
      "i:  33  num:  0.7448745137387217  action:  1  reward:  2  Q-values:  [0.68, 0.34]\n",
      "i:  34  num:  0.5100084527755381  action:  0  reward:  4  Q-values:  [0.72, 0.34]\n",
      "i:  35  num:  0.8896099904852536  action:  0  reward:  4  Q-values:  [0.76, 0.34]\n",
      "i:  36  num:  0.3488007465251235  action:  1  reward:  2  Q-values:  [0.76, 0.36]\n",
      "i:  37  num:  0.9957460062669848  action:  1  reward:  2  Q-values:  [0.76, 0.38]\n",
      "i:  38  num:  0.16834889087575922  action:  1  reward:  2  Q-values:  [0.76, 0.39999999999999997]\n",
      "i:  39  num:  0.5617223863024151  action:  1  reward:  2  Q-values:  [0.76, 0.42]\n",
      "i:  40  num:  0.8183434641496578  action:  1  reward:  2  Q-values:  [0.76, 0.44]\n",
      "i:  41  num:  0.6091995224201235  action:  1  reward:  2  Q-values:  [0.76, 0.45999999999999996]\n",
      "i:  42  num:  0.04571468536432277  action:  1  reward:  2  Q-values:  [0.76, 0.48]\n",
      "i:  43  num:  0.8139599985937443  action:  1  reward:  2  Q-values:  [0.76, 0.49999999999999994]\n",
      "i:  44  num:  0.403117445627298  action:  1  reward:  2  Q-values:  [0.76, 0.5199999999999999]\n",
      "i:  45  num:  0.852164256524478  action:  1  reward:  2  Q-values:  [0.76, 0.5399999999999999]\n",
      "i:  46  num:  0.37216436017098775  action:  1  reward:  2  Q-values:  [0.76, 0.5599999999999999]\n",
      "i:  47  num:  0.2104095622191543  action:  1  reward:  2  Q-values:  [0.76, 0.5799999999999998]\n",
      "i:  48  num:  0.41908827371443547  action:  0  reward:  4  Q-values:  [0.7999999999999999, 0.5799999999999998]\n",
      "i:  49  num:  0.029388194866140638  action:  1  reward:  2  Q-values:  [0.7999999999999999, 0.5999999999999999]\n",
      "i:  50  num:  0.22159132346055788  action:  1  reward:  2  Q-values:  [0.7999999999999999, 0.6199999999999999]\n",
      "i:  51  num:  0.4445236379928028  action:  1  reward:  2  Q-values:  [0.7999999999999999, 0.6399999999999999]\n",
      "i:  52  num:  0.2278233955250354  action:  0  reward:  4  Q-values:  [0.84, 0.6399999999999999]\n",
      "i:  53  num:  0.1866064442745763  action:  0  reward:  4  Q-values:  [0.88, 0.6399999999999999]\n",
      "i:  54  num:  0.2736289876736925  action:  1  reward:  2  Q-values:  [0.88, 0.6599999999999999]\n",
      "i:  55  num:  0.7429044583101132  action:  0  reward:  4  Q-values:  [0.9199999999999999, 0.6599999999999999]\n",
      "i:  56  num:  0.9374858365419503  action:  1  reward:  2  Q-values:  [0.9199999999999999, 0.6799999999999998]\n",
      "i:  57  num:  0.8246079172295852  action:  0  reward:  4  Q-values:  [0.96, 0.6799999999999998]\n",
      "i:  58  num:  0.8212569505321575  action:  0  reward:  4  Q-values:  [0.9999999999999999, 0.6799999999999998]\n",
      "i:  59  num:  0.8370799375318702  action:  0  reward:  4  Q-values:  [1.0399999999999998, 0.6799999999999998]\n",
      "i:  60  num:  0.6169843761587583  action:  0  reward:  4  Q-values:  [1.0799999999999998, 0.6799999999999998]\n",
      "i:  61  num:  0.17410023627042748  action:  0  reward:  4  Q-values:  [1.1199999999999999, 0.6799999999999998]\n",
      "i:  62  num:  0.7716887581237862  action:  0  reward:  4  Q-values:  [1.1599999999999997, 0.6799999999999998]\n",
      "i:  63  num:  0.7186881792035356  action:  0  reward:  4  Q-values:  [1.1999999999999997, 0.6799999999999998]\n",
      "i:  64  num:  0.887500345404199  action:  0  reward:  4  Q-values:  [1.2399999999999998, 0.6799999999999998]\n",
      "i:  65  num:  0.42927148096612333  action:  1  reward:  2  Q-values:  [1.2399999999999998, 0.6999999999999998]\n",
      "i:  66  num:  0.14020507708866525  action:  0  reward:  4  Q-values:  [1.2799999999999998, 0.6999999999999998]\n",
      "i:  67  num:  0.4325121698077027  action:  0  reward:  4  Q-values:  [1.3199999999999998, 0.6999999999999998]\n",
      "i:  68  num:  0.7538087066852512  action:  1  reward:  2  Q-values:  [1.3199999999999998, 0.7199999999999999]\n",
      "i:  69  num:  0.589872613751951  action:  0  reward:  4  Q-values:  [1.3599999999999997, 0.7199999999999999]\n",
      "i:  70  num:  0.6445719194229075  action:  0  reward:  4  Q-values:  [1.3999999999999997, 0.7199999999999999]\n",
      "i:  71  num:  0.5679141025712394  action:  1  reward:  2  Q-values:  [1.3999999999999997, 0.7399999999999999]\n",
      "i:  72  num:  0.6627272603128029  action:  1  reward:  2  Q-values:  [1.3999999999999997, 0.7599999999999999]\n",
      "i:  73  num:  0.7939280578360608  action:  1  reward:  2  Q-values:  [1.3999999999999997, 0.7799999999999998]\n",
      "i:  74  num:  0.18107263840813959  action:  1  reward:  2  Q-values:  [1.3999999999999997, 0.7999999999999998]\n",
      "i:  75  num:  0.5162590689802459  action:  0  reward:  4  Q-values:  [1.4399999999999997, 0.7999999999999998]\n",
      "i:  76  num:  0.026374640687109818  action:  0  reward:  4  Q-values:  [1.4799999999999998, 0.7999999999999998]\n",
      "i:  77  num:  0.9440466468697397  action:  0  reward:  4  Q-values:  [1.5199999999999998, 0.7999999999999998]\n",
      "i:  78  num:  0.818722287437148  action:  1  reward:  2  Q-values:  [1.5199999999999998, 0.8199999999999998]\n",
      "i:  79  num:  0.43565715349303613  action:  0  reward:  4  Q-values:  [1.5599999999999996, 0.8199999999999998]\n",
      "i:  80  num:  0.6451089628982771  action:  1  reward:  2  Q-values:  [1.5599999999999996, 0.8399999999999999]\n",
      "i:  81  num:  0.6572516100993825  action:  0  reward:  4  Q-values:  [1.5999999999999996, 0.8399999999999999]\n",
      "i:  82  num:  0.6894062662172371  action:  1  reward:  2  Q-values:  [1.5999999999999996, 0.8599999999999999]\n",
      "i:  83  num:  0.7531872295593329  action:  1  reward:  2  Q-values:  [1.5999999999999996, 0.8799999999999998]\n",
      "i:  84  num:  0.3841431531028364  action:  0  reward:  4  Q-values:  [1.6399999999999997, 0.8799999999999998]\n",
      "i:  85  num:  0.9323247679943677  action:  1  reward:  2  Q-values:  [1.6399999999999997, 0.8999999999999998]\n",
      "i:  86  num:  0.0025218752944096146  action:  0  reward:  4  Q-values:  [1.6799999999999997, 0.8999999999999998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  87  num:  0.5603851251101524  action:  1  reward:  2  Q-values:  [1.6799999999999997, 0.9199999999999998]\n",
      "i:  88  num:  0.3248496219873651  action:  1  reward:  2  Q-values:  [1.6799999999999997, 0.9399999999999998]\n",
      "i:  89  num:  0.817077575711092  action:  0  reward:  4  Q-values:  [1.7199999999999998, 0.9399999999999998]\n",
      "i:  90  num:  0.7046655216661141  action:  0  reward:  4  Q-values:  [1.7599999999999996, 0.9399999999999998]\n",
      "i:  91  num:  0.8871347279805294  action:  0  reward:  4  Q-values:  [1.7999999999999996, 0.9399999999999998]\n",
      "i:  92  num:  0.17786709160141367  action:  1  reward:  2  Q-values:  [1.7999999999999996, 0.9599999999999999]\n",
      "i:  93  num:  0.44590224826086944  action:  0  reward:  4  Q-values:  [1.8399999999999996, 0.9599999999999999]\n",
      "i:  94  num:  0.9561646613113443  action:  0  reward:  4  Q-values:  [1.8799999999999997, 0.9599999999999999]\n",
      "i:  95  num:  0.5034665765062244  action:  1  reward:  2  Q-values:  [1.8799999999999997, 0.9799999999999998]\n",
      "i:  96  num:  0.6516404932383221  action:  1  reward:  2  Q-values:  [1.8799999999999997, 0.9999999999999998]\n",
      "i:  97  num:  0.6388376861693754  action:  1  reward:  2  Q-values:  [1.8799999999999997, 1.0199999999999998]\n",
      "i:  98  num:  0.6674322589786041  action:  0  reward:  4  Q-values:  [1.9199999999999997, 1.0199999999999998]\n",
      "i:  99  num:  0.5512214116511054  action:  0  reward:  4  Q-values:  [1.9599999999999995, 1.0199999999999998]\n"
     ]
    }
   ],
   "source": [
    "# init theta to random values\n",
    "theta = np.random.randn(2) \n",
    "# number of iterations\n",
    "epochs = 100\n",
    "# measurement results (probs. of ket zero and ket one)\n",
    "M = np.zeros(epochs)\n",
    "# environment probability\n",
    "p = 0.9 # adversary likely to do the same as agent\n",
    "p = 0.0 # adversary unlikely to do the same as agent\n",
    "# rewards\n",
    "R = [4, 2] \n",
    "# Q-value (total reward associated with actions)\n",
    "Q = [0, 0]\n",
    "# learning rate\n",
    "alpha = 0.01\n",
    "# main loop\n",
    "for i in range(epochs):\n",
    "    # agent has a random behavior, select random action\n",
    "    a = np.random.randint(2, size=1)[0]\n",
    "    # agent has a pattern behavior, most likely take the loop\n",
    "    #a = 0; \n",
    "    #num = np.random.random(1)[0]\n",
    "    #if num > 0.9:\n",
    "    #    r = 1;\n",
    "    # agent has a pattern behavior, most likely take the bypass\n",
    "    #a = 1; \n",
    "    #num = np.random.random(1)[0]\n",
    "    #if num > 0.9:\n",
    "    #    r = 0;    \n",
    "    # determine reward\n",
    "    num = np.random.random(1)[0]\n",
    "    r = 0\n",
    "    if num > p:\n",
    "        r = R[a]\n",
    "    # Bellman equation\n",
    "    Q[a] = (1-alpha)*Q[a] + alpha*(r + Q[a])\n",
    "    print(\"i: \", i,\" num: \", num,\" action: \", a, \" reward: \", r, \" Q-values: \", Q)\n",
    "    if (Q[0]+Q[1]) > 0:\n",
    "        theta = update(theta, Q[0]/(Q[0]+Q[1]))\n",
    "    M[i] = W(theta)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(M, 'bs', label='take loop')\n",
    "plt.plot(1-M, 'g^', label='take bypass')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Probability')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
